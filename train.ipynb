{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchsummary import summary\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "id": "1517b481f3cc9d08"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Cassava Leaf Disease**",
   "id": "f47f66150de5fd18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **Load Dataset**",
   "id": "4752d81156fdcf00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Download Dataset**",
   "id": "757d18bfe5074ee1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!curl https://storage.googleapis.com/emcassavadata/cassavaleafdata.zip  -O /cassavaleafdata.zip\n",
   "id": "46ab13aa73ce96f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!unzip /content/cassavaleafdata.zip",
   "id": "a08c96599f78b004"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Read Dataset**",
   "id": "c31860792c3623a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_paths = {\n",
    "\t'train': './train',\n",
    "\t'valid': './validation',\n",
    "\t'test': './test'\n",
    "}"
   ],
   "id": "6ff1627804a36e45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from imutils import paths\n",
    "\n",
    "\n",
    "def show_labels(data_paths):\n",
    "\tfig, ax = plt.subplots(1, len(data_paths), figsize = (12, 6))\n",
    "\tfor idx, (key, sub_dir) in enumerate(data_paths.items()):\n",
    "\t\tlabels = os.listdir(sub_dir)\n",
    "\t\tlist_data = []\n",
    "\t\tfor label in labels:\n",
    "\t\t\timage_files = list(paths.list_images(os.path.join(sub_dir, label)))\n",
    "\t\t\tlist_data.append(len(image_files))\n",
    "\t\tax[idx].bar(labels, list_data)\n",
    "\t\tax[idx].set_title(key)\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "show_labels(data_paths)\n",
    "\n",
    "labels_dict = {\n",
    "\t\"cbb\": \"Cassava Bacterial Blight (CBB)\",\n",
    "\t\"cbsd\": \"Cassava Brown Streak Disease (CBSD)\",\n",
    "\t\"cgm\": \"Cassava Green Mottle (CGM)\",\n",
    "\t\"cmd\": \"Cassava Mosaic Disease (CMD)\",\n",
    "\t\"healthy\": \"Healthy\"\n",
    "}\n",
    "\n",
    "\n",
    "def plot_images(data_dir, label, num_sample = 6):\n",
    "\tdata_dir = os.path.join(data_dir, label)\n",
    "\timage_files = list(paths.list_images(data_dir))[:num_sample]\n",
    "\tfig, ax = plt.subplots(2, num_sample // 2, figsize = (14, 7))\n",
    "\tfor i, image_dir in enumerate(image_files):\n",
    "\t\timg = Image.open(image_dir)\n",
    "\t\tlabel = image_dir.split('/')[-2]\n",
    "\t\tax[i // (num_sample // 2)][i % (num_sample // 2)].imshow(img)\n",
    "\t\tax[i // (num_sample // 2)][i % (num_sample // 2)].set_title(labels_dict[label])\n",
    "\t\tax[i // (num_sample // 2)][i % (num_sample // 2)].axis('off')\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "plot_images(data_paths['train'], label = \"cbb\")\n",
    "\n",
    "plot_images(data_paths['train'], label = \"cbsd\")\n",
    "\n",
    "plot_images(data_paths['train'], label = \"cgm\")\n",
    "\n",
    "plot_images(data_paths['train'], label = \"cmd\")\n",
    "\n",
    "plot_images(data_paths['train'], label = \"healthy\")\n"
   ],
   "id": "5efbd3d9c74eb8a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **Preprocessing**",
   "id": "602b5a8a6e8a12fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load image from path\n",
    "def loader(path):\n",
    "\treturn Image.open(path)\n",
    "\n",
    "\n",
    "img_size = 150\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "\ttransforms.Resize((150, 150)),\n",
    "\ttransforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\n",
    "\troot = data_paths['train'],\n",
    "\tloader = loader,\n",
    "\ttransform = train_transforms\n",
    ")\n",
    "valid_data = datasets.ImageFolder(\n",
    "\troot = data_paths['valid'],\n",
    "\ttransform = train_transforms\n",
    ")\n",
    "test_data = datasets.ImageFolder(\n",
    "\troot = data_paths['test'],\n",
    "\ttransform = train_transforms\n",
    ")"
   ],
   "id": "c5afcc8959abebcd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **Dataloader**\n",
   "id": "f9c5133c6588decc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "\ttrain_data,\n",
    "\tshuffle = True,\n",
    "\tbatch_size = BATCH_SIZE\n",
    ")\n",
    "valid_dataloader = data.DataLoader(\n",
    "\tvalid_data,\n",
    "\tbatch_size = BATCH_SIZE\n",
    ")\n",
    "test_dataloader = data.DataLoader(\n",
    "\ttest_data,\n",
    "\tbatch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "len(train_dataloader)\n",
    "\n",
    "inputs, labels = next(iter(train_dataloader))"
   ],
   "id": "44538b0fd3f97676"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **Model**",
   "id": "d5d0f2924dfd3391"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from model import LeNetClassifier",
   "id": "bb78d9962cca5755"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_classes = len(train_data.classes)\n",
    "num_classes"
   ],
   "id": "afd7386658b40f28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lenet_model = LeNetClassifier(num_classes)\n",
    "\n",
    "summary(lenet_model, (3, 150, 150))\n",
    "\n",
    "inputs.shape"
   ],
   "id": "8adbe2df14b116e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictions = lenet_model(inputs)\n",
    "\n",
    "predictions"
   ],
   "id": "e6b4b2a0e570bd16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **Loss & Optimizer**",
   "id": "4fbc0aef6a186fba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "optimizer = optim.Adam(lenet_model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss = criterion(predictions, labels)\n",
    "loss"
   ],
   "id": "fdf325f4f49515a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lenet_model.to(device)"
   ],
   "id": "9f2ce89f0ddbbd19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **Trainer**",
   "id": "cdae242e2688c31d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def train(model, optimizer, criterion, train_dataloader, device, epoch = 0, log_interval = 15):\n",
    "\tmodel.train()\n",
    "\ttotal_acc, total_count = 0, 0\n",
    "\tlosses = []\n",
    "\tstart_time = time.time()\n",
    "\n",
    "\tfor idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "\t\tinputs = inputs.to(device)\n",
    "\t\tlabels = labels.to(device)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\tpredictions = model(inputs)\n",
    "\n",
    "\t\t# compute loss\n",
    "\t\tloss = criterion(predictions, labels)\n",
    "\t\tlosses.append(loss.item())\n",
    "\n",
    "\t\t# backward\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\ttotal_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "\t\ttotal_count += labels.size(0)\n",
    "\t\tif idx % log_interval == 0 and idx > 0:\n",
    "\t\t\telapsed = time.time() - start_time\n",
    "\t\t\tprint(\n",
    "\t\t\t\t\"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "\t\t\t\t\"| accuracy {:8.3f}\".format(\n",
    "\t\t\t\t\tepoch, idx, len(train_dataloader), total_acc / total_count\n",
    "\t\t\t\t)\n",
    "\t\t\t)\n",
    "\t\t\ttotal_acc, total_count = 0, 0\n",
    "\t\t\tstart_time = time.time()\n",
    "\n",
    "\tepoch_acc = total_acc / total_count\n",
    "\tepoch_loss = sum(losses) / len(losses)\n",
    "\treturn epoch_acc, epoch_loss\n",
    "\n",
    "\n",
    "train_acc, train_loss = train(lenet_model, optimizer, criterion, train_dataloader, device)\n",
    "\n",
    "train_acc, train_loss\n"
   ],
   "id": "bd4622cf4eb04327"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def evaluate(model, criterion, valid_dataloader, device):\n",
    "\tmodel.eval()\n",
    "\ttotal_acc, total_count = 0, 0\n",
    "\tlosses = []\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tfor idx, (inputs, labels) in enumerate(valid_dataloader):\n",
    "\t\t\tinputs = inputs.to(device)\n",
    "\t\t\tlabels = labels.to(device)\n",
    "\n",
    "\t\t\tpredictions = model(inputs)\n",
    "\n",
    "\t\t\tloss = criterion(predictions, labels)\n",
    "\t\t\tlosses.append(loss.item())\n",
    "\n",
    "\t\t\ttotal_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "\t\t\ttotal_count += labels.size(0)\n",
    "\n",
    "\tepoch_acc = total_acc / total_count\n",
    "\tepoch_loss = sum(losses) / len(losses)\n",
    "\treturn epoch_acc, epoch_loss\n",
    "\n",
    "\n",
    "eval_acc, eval_loss = evaluate(lenet_model, criterion, valid_dataloader, device)\n",
    "\n",
    "eval_acc, eval_loss"
   ],
   "id": "fb2f0945d4f2be0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **Training**\n",
   "id": "50489fb0c3575940"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_classes = len(train_data.classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lenet_model = LeNetClassifier(num_classes)\n",
    "lenet_model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 2e-4\n",
    "optimizer = optim.Adam(lenet_model.parameters(), learning_rate)\n",
    "\n",
    "num_epochs = 10\n",
    "save_model = './model'\n",
    "\n",
    "train_accs, train_losses = [], []\n",
    "eval_accs, eval_losses = [], []\n",
    "best_loss_eval = 100\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "\tepoch_start_time = time.time()\n",
    "\t# Training\n",
    "\ttrain_acc, train_loss = train(lenet_model, optimizer, criterion, train_dataloader, device, epoch, log_interval = 10)\n",
    "\ttrain_accs.append(train_acc)\n",
    "\ttrain_losses.append(train_loss)\n",
    "\n",
    "\t# Evaluation\n",
    "\teval_acc, eval_loss = evaluate(lenet_model, criterion, valid_dataloader, device)\n",
    "\teval_accs.append(eval_acc)\n",
    "\teval_losses.append(eval_loss)\n",
    "\n",
    "\t# Save best model\n",
    "\tif eval_loss < best_loss_eval:\n",
    "\t\ttorch.save(lenet_model.state_dict(), save_model + '/lenet_model.pt')\n",
    "\n",
    "\t# Print loss, acc end epoch\n",
    "\tprint(\"-\" * 59)\n",
    "\tprint(\n",
    "\t\t\"| End of epoch {:3d} | Time: {:5.2f}s | Train Accuracy {:8.3f} | Train Loss {:8.3f} \"\n",
    "\t\t\"| Valid Accuracy {:8.3f} | Valid Loss {:8.3f} \".format(\n",
    "\t\t\tepoch, time.time() - epoch_start_time, train_acc, train_loss, eval_acc, eval_loss\n",
    "\t\t)\n",
    "\t)\n",
    "\tprint(\"-\" * 59)\n",
    "\n",
    "\t# Load best model\n",
    "\tlenet_model.load_state_dict(torch.load(save_model + '/lenet_model.pt', weights_only = True))\n",
    "\tlenet_model.eval()\n",
    "\n",
    "\n",
    "def plot_result(num_epochs, train_accs, eval_accs, train_losses, eval_losses):\n",
    "\tepochs = list(range(num_epochs))\n",
    "\tfig, axs = plt.subplots(nrows = 1, ncols = 2, figsize = (12, 6))\n",
    "\taxs[0].plot(epochs, train_accs, label = \"Training\")\n",
    "\taxs[0].plot(epochs, eval_accs, label = \"Evaluation\")\n",
    "\taxs[1].plot(epochs, train_losses, label = \"Training\")\n",
    "\taxs[1].plot(epochs, eval_losses, label = \"Evaluation\")\n",
    "\taxs[0].set_xlabel(\"Epochs\")\n",
    "\taxs[1].set_xlabel(\"Epochs\")\n",
    "\taxs[0].set_ylabel(\"Accuracy\")\n",
    "\taxs[1].set_ylabel(\"Loss\")\n",
    "\tplt.legend()\n",
    "\n",
    "\n",
    "plot_result(num_epochs, train_accs, eval_accs, train_losses, eval_losses)"
   ],
   "id": "809c6495c724da67"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **Evaluation & Prediction**\n",
   "id": "de67c6b6a026c3e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_acc, test_loss = evaluate(lenet_model, criterion, test_dataloader, device)\n",
    "test_acc, test_loss"
   ],
   "id": "2c3667c51e581550"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **Inference**",
   "id": "e7c68f3c890a530b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(model_path, num_classes = 5):\n",
    "\tlenet_model = LeNetClassifier(num_classes)\n",
    "\tlenet_model.load_state_dict(torch.load(model_path, weights_only = True))\n",
    "\tlenet_model.eval()\n",
    "\treturn lenet_model\n",
    "\n",
    "\n",
    "def inference(img_path, model):\n",
    "\timage = Image.open(img_path)\n",
    "\timg_size = 150\n",
    "\n",
    "\timg_transform = transforms.Compose([\n",
    "\t\ttransforms.Resize((150, 150)),\n",
    "\t\ttransforms.ToTensor(),\n",
    "\t])\n",
    "\timg_new = img_transform(image)\n",
    "\timg_new = torch.unsqueeze(img_new, 0)\n",
    "\twith torch.no_grad():\n",
    "\t\tpredictions = model(img_new)\n",
    "\tpreds = nn.Softmax(dim = 1)(predictions)\n",
    "\tp_max, yhat = torch.max(preds.data, 1)\n",
    "\treturn p_max.item(), yhat.item()\n",
    "\n",
    "\n",
    "model = load_model('lenet_model_cassava.pt')\n",
    "preds = inference('data/test/cbsd/test-cbsd-1.jpg', model)\n",
    "preds\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_data.class_to_idx",
   "id": "a8e4053ea20e095f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "idx2label = {\n",
    "\t0: 'cbb',\n",
    "\t1: 'cbsd',\n",
    "\t2: 'cgm',\n",
    "\t3: 'cmd',\n",
    "\t4: 'healthy',\n",
    "}\n",
    "\n",
    "idx2label[4]"
   ],
   "id": "e19dde5a2a4530d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
